[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mohammad Sayeef Alam",
    "section": "",
    "text": "I am a doctoral candidate at the Norwegian University of Science and Technology in Trondheim, with a strong background in health data analysis. My research focuses on statistical genetics and gastrointestinal diseases, where I work with tools like R, Python, and Bash.\nIn my spare time, I enjoy creating visualizations and building interactive applications to support decision-making in healthcare, and I’m driven by the chance to use programming to address challenges in healthcare using real-world data.\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "I am a final-year PhD candidate in Genetic Epidemiology at the Norwegian University of Science and Technology (NTNU) in Trondheim. My research focuses on statistical genetics and gastrointestinal diseases, where I analyze high-dimensional genetic data and link it with real-world health records to uncover differences across population groups.\nI hold dual master’s degrees in Biostatistics and a bachelor’s degree in Statistics. Over the past six years, I have gained experience working with diverse health-related datasets, applying a range of statistical methods in epidemiology, biostatistics, clinical trials, and genetics.\nI have hands-on experience with tools such as R, STATA, SAS, Excel (including VBA), and Bash. I particularly enjoy building interactive applications using Shiny to support data-driven decision-making. I am technically minded and strive to communicate complex ideas in a way that is accessible to different audiences. I value a positive working environment and am always open to new challenges. I am fluent in English and still learning Norwegian.\nOutside of research, I enjoy hiking, skiing, and watching anime. I’m also learning to swim. Community and connection are important to me—I volunteer at the MSiT mosque in Trondheim during Ramadan, helping serve meals to people of all backgrounds.\nMy career goal is to contribute to evidence synthesis and informed decision-making in healthcare through rigorous research, thoughtful analytics, and collaborative science that benefits communities worldwide.\nSee ya later ⛷️\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "blogs.html",
    "href": "blogs.html",
    "title": "MSA",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\nhealthecon\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmcmc\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nprs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLearnings from first R package development\n\n\n\nR\n\n\nProgramming\n\n\n\nBasic checks and debugging while R package development\n\n\n\nAug 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComplete Git and SSH Setup Guide: From Zero to Push\n\n\n\nTerminal\n\n\nProgramming\n\n\n\nThis guide provides step-by-step instructions to connect git, clone repo and push commits\n\n\n\nJul 11, 2025\n\n\n\n\n\n\n\n\n\n\n\n\nFrom Missing to Meaningful: Beginner’s Guide to Multiple Imputation\n\n\n\nR\n\n\nProgramming\n\n\n\nA beginner-friendly guide to handling missing data using Multiple Imputation with the mice package in R.\n\n\n\nDec 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBeyond QC: A Practical Guide to GWAS with SAIGE\n\n\n\nGenetics\n\n\nMethods\n\n\nBash\n\n\nR\n\n\n\nA hands-on guide for performing GWAS after preliminary QC, covering phenotype preparation, and association testing using SAIGE.\n\n\n\nApr 21, 2024\n\n\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "workshops.html",
    "href": "workshops.html",
    "title": "Certifications",
    "section": "",
    "text": "2025\n\n  \n\n\n\n2024\n\n  \n  \n\n\n  \n  \n\n\n\n2021\n\n  \n\n\n\n2020\n\n\n   \n\n  \n\n\n  \n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Download PDF"
  },
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "MSA",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nSep 10, 2024\n\n\nAssessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.\n\n\nMohammad Sayeef Alam, Rebecka Hjort, Kristian Hveem, Knut E. A. Lundin, Iris H. Jonkers, Ludvig M. Sollid, Eivind Ness-Jensen\n\n\n\n\nSep 9, 2024\n\n\nThe IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.\n\n\nMohammad Sayeef Alam, Laurent F Thomas, Ben Brumpton, Kristian Hveem, Knut E A Lundin, Sebo Withoff, Iris H Jonkers, Ludvig M Sollid, Rebecka Hjort, Eivind Ness Jensen\n\n\n\n\nSep 6, 2024\n\n\nAssessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.\n\n\nMohammad Sayeef Alam, Laurent F Thomas, Ben Brumpton, Kristian Hveem, Knut E A Lundin, Sebo Withoff, Iris H Jonkers, Ludvig M Sollid, Rebecka Hjort, Eivind Ness Jensen\n\n\n\n\nSep 5, 2024\n\n\nThe IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.\n\n\nMohammad Sayeef Alam, Laurent F Thomas, Ben Brumpton, Kristian Hveem, Knut E A Lundin, Sebo Withoff, Iris H Jonkers, Ludvig M Sollid, Rebecka Hjort, Eivind Ness Jensen\n\n\n\n\nNov 4, 2019\n\n\nPrevalence of communicable diseases and its epidemiological correlates in major urban populated states of India: Evidence from a nationally representative sample\n\n\nMohammad Sayeef Alam, Balram Paswan, Mohammed Illias Sheikh\n\n\n\n\nDec 18, 2018\n\n\nShifting Paradigm in the Cause of Maternal Mortality in West Bengal: A Facility and Community-Based Mixed Method Approach Study\n\n\nMohammad Sayeef Alam, Md Illias Kanchan Sk\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "MSA",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nPackaging MOON in R\n\n\nFrom Excel to R - Advancing Decision Analytics for Cost-Effective Health Interventions for Obesity\n\n\n\nR\n\n\nExcel\n\n\n\n\n\n\n\n\n\nMohammad Sayeef Alam, Gudrun Maria Waaler Bjørnelv\n\n\n\n\n\n\n\n\n\n\n\n\nQALY Shortfall calculator for Nordics\n\n\nAn RShiny app to estimate the absolute and proportion shortfall in QALY for the five Nordic countries\n\n\n\nR\n\n\nShiny\n\n\n\n\n\n\n\n\n\nMohammad Sayeef Alam, Gudrun Maria Waaler Bjørnelv, Christina Hansen Edwards, Yvonne Anne Michel, Jon Magnussen\n\n\n\n\n\n\nNo matching items\n\n Back to top"
  },
  {
    "objectID": "resume.html#associate-parexel-remote-india",
    "href": "resume.html#associate-parexel-remote-india",
    "title": "Curriculum Vitae",
    "section": "Associate, Parexel – Remote, India",
    "text": "Associate, Parexel – Remote, India\nJuly 2021 – February 2022\n\nDeveloped interactive platforms (e.g., RShiny) for economic evaluations.\nPerformed statistical analyses aligned with HTA guidelines across multiple disease areas.\nAutomated dashboards (Excel/VBA) for clinical endpoint visualization.\nCoordinated projects and managed client expectations.\nContributed to SAPs and validated datasets.\nPresented analytical results to stakeholders and refined deliverables."
  },
  {
    "objectID": "resume.html#phd-ntnu-trondheim-norway",
    "href": "resume.html#phd-ntnu-trondheim-norway",
    "title": "Curriculum Vitae",
    "section": "PhD, NTNU – Trondheim, Norway",
    "text": "PhD, NTNU – Trondheim, Norway\nApril 2022 – Current\n\nApplied advanced statistical methods to genetic and registry data.\nDesigned analysis pipelines to improve efficiency.\nPresented findings at conferences and published in peer-reviewed journals.\nCollaborated with external research groups.\nBuilt academic networks and secured over 150,000 NOK in funding."
  },
  {
    "objectID": "resume.html#nordic-shortfall-calculator",
    "href": "resume.html#nordic-shortfall-calculator",
    "title": "Curriculum Vitae",
    "section": "Nordic Shortfall Calculator",
    "text": "Nordic Shortfall Calculator\n\nDeveloped a model to calculate shortfall for Denmark, Finland, Norway, and Sweden.\nProvides estimates of QALE based on EQ-5D/3D values.\nIncludes comparative options, discount rates, and dynamic inputs."
  },
  {
    "objectID": "projects.html#global-biodiversity-shiny-dashboard-for-poland",
    "href": "projects.html#global-biodiversity-shiny-dashboard-for-poland",
    "title": "Mohammad Sayeef Alam",
    "section": "",
    "text": "The GBIF Data Explorer is a web application that allows users to explore and analyze biodiversity data for Poland from the Global Biodiversity Information Facility (GBIF) database.\nThe app is built using the Shiny package for R. It includes several visualizations and filters created using the following packages: DT, shiny, shinyWidgets, shinythemes, shinyjs, bslib, bsicons, lubridate, leaflet, highcharter…. Check out the shiny dashboard"
  },
  {
    "objectID": "projects.html#collaborating-between-python-and-r-using-reticulate",
    "href": "projects.html#collaborating-between-python-and-r-using-reticulate",
    "title": "Mohammad Sayeef Alam",
    "section": "Collaborating between Python and R using Reticulate",
    "text": "Collaborating between Python and R using Reticulate\n\n\n\n\n\n\nBoth R and Python are powerful data science languages and can be used to accomplish end-to-end analytics projects. Reticulate makes it easy to collaborate and talk between the two languages. I think of it as a translator on my fingertips.\nMy teammate and I participated in Microsoft hackathon where we accessed data from APIs using Python, pulled the output in R using Reticulate and created visualizations to derive business insights using Ggplot2… Check out how"
  },
  {
    "objectID": "projects.html#data-visualizations---animation-and-interactivity-using-gganimate-and-plotly",
    "href": "projects.html#data-visualizations---animation-and-interactivity-using-gganimate-and-plotly",
    "title": "Mohammad Sayeef Alam",
    "section": "Data visualizations - Animation and Interactivity using Gganimate and Plotly",
    "text": "Data visualizations - Animation and Interactivity using Gganimate and Plotly\n\n\nAnimation brings in a key component of analysis where the third parameter you want to animate is not directly visible in your plot. Sometimes it can tell a powerful story and sometimes it can just add some flair to an otherwise low-key story.\nThis blog goes through examples and code to show how easy it is to use gganimate and plotly packages to animate your data visualizations and make them interactive…. Continue reading"
  },
  {
    "objectID": "projects.html#sales-forecasting-and-anomaly-detection-shiny-dashboard",
    "href": "projects.html#sales-forecasting-and-anomaly-detection-shiny-dashboard",
    "title": "Mohammad Sayeef Alam",
    "section": "Sales forecasting and anomaly detection Shiny dashboard",
    "text": "Sales forecasting and anomaly detection Shiny dashboard\n\n\n\n\n\n\nThis dashboard, built with Shiny Flex capability, looks at data from EverythingYouWillNeed.com website (fake data) to report out odaily product sales. You can select the product, the dates to analyze and click on apply to replicate the report, check sales forecast and anomalies for the specific product choice.\nGiving your stakeholders the ability to play with product grain forecast and anomaly detection is a great was to get them on-board prior to deploying any model at scale. This Shiny dashboard was built specifically for that purpose…. Link to play with the Shiny dashboard"
  },
  {
    "objectID": "projects.html#qaly-shortfall-calculator-for-nordics",
    "href": "projects.html#qaly-shortfall-calculator-for-nordics",
    "title": "MSA",
    "section": "",
    "text": "The Nordic Shortfall Calculator is a web application that allows users to explore and analyze the QALY shortfall based on updated utility values as well as compare them to previous values or even values used by other Nordic countries.\nThe app is built using the Shiny package for R. It includes several visualizations and filters created using the following packages: DT, shiny, shinyWidgets, shinythemes, shinyjs, bslib, bsicons, lubridate, leaflet, highcharter…. Check out the shiny app"
  },
  {
    "objectID": "projects.html#packaging-moon",
    "href": "projects.html#packaging-moon",
    "title": "MSA",
    "section": "",
    "text": "Both R and Excel are powerful data science tools and can be used to accomplish end-to-end analytics projects.\nGudrun and I, are trying to move the decision analytics model built on excel to R, to promote open-access science. The decision analytics model runs a Markov model to assess the cost effectiveness of intervention for obesity."
  },
  {
    "objectID": "talks.html#lab-reports",
    "href": "talks.html#lab-reports",
    "title": "Team Documents",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "talks.html#meeting-notes",
    "href": "talks.html#meeting-notes",
    "title": "Team Documents",
    "section": "Meeting Notes",
    "text": "Meeting Notes\n\n\n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html#about-me",
    "href": "about.html#about-me",
    "title": "Mohammad Sayeef Alam",
    "section": "",
    "text": "I’m a doctoral candidate at the Norwegian University of Science and Technology (NTNU) in Trondheim, where my research focuses on statistical genetics and gastrointestinal diseases. With a strong foundation in statistics and biostatistics, I work with real-world health data to support better decision-making in healthcare.\nMy work involves applying advanced statistical methods and programming in R, Python, and bash. I also enjoy building interactive tools—such as Shiny apps—that help make complex data more accessible and actionable. I’m especially motivated by the opportunity to use programming to address real-world challenges in healthcare.\nWhat motivates me most is the opportunity to apply programming and analytics to real-world challenges in healthcare. I find it rewarding to contribute to projects that have practical impact, whether through research, collaboration, or tool development.\nBeyond research, I value community and connection. During the month of Ramadan, I volunteer at the MSiT mosque in Trondheim, helping serve food to people of all faiths—whether they are breaking their fast or simply sharing a warm meal with friends. It’s a small way to contribute to a welcoming and inclusive environment.\nOutside of work, I enjoy hiking, swimming, improving my Norwegian and cooking for others. These activities help me stay grounded and bring balance to my academic life. I’m always eager to learn, collaborate, and contribute to projects that make a meaningful impact."
  },
  {
    "objectID": "blogs/rpackagedev.html",
    "href": "blogs/rpackagedev.html",
    "title": "Learnings from first R package development",
    "section": "",
    "text": "This documentation is for individuals such as me, to create more than basic R package while debugging common errors, warnings and notes."
  },
  {
    "objectID": "blogs/gitsetup.html",
    "href": "blogs/gitsetup.html",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "",
    "text": "Whether you’re a beginner developer or switching to a new machine, setting up Git with SSH authentication can seem daunting. This comprehensive guide will walk you through every step to get you from a fresh installation to pushing your first commit securely.\nBy the end of this guide, you’ll be able to: - Configure Git with your identity - Generate and set up SSH keys for secure authentication - Create and manage local Git repositories - Connect your local work to remote repositories (GitHub, GitLab, etc.) - Understand the basic Git workflow for daily development"
  },
  {
    "objectID": "blogs/rpackagedev.html#step-4.5-perform-checks",
    "href": "blogs/rpackagedev.html#step-4.5-perform-checks",
    "title": "Learnings from first R package development",
    "section": "Step 4.5: Perform checks",
    "text": "Step 4.5: Perform checks\n\nCodedevtools::document()\ndevtools::check()"
  },
  {
    "objectID": "blogs/rpackagedev.html#step-6.5-perform-checks",
    "href": "blogs/rpackagedev.html#step-6.5-perform-checks",
    "title": "Learnings from first R package development",
    "section": "Step 6.5: Perform checks",
    "text": "Step 6.5: Perform checks\n\nCodedevtools::document()\ndevtools::check()"
  },
  {
    "objectID": "projects/nsc.html",
    "href": "projects/nsc.html",
    "title": "QALY Shortfall calculator for Nordics",
    "section": "",
    "text": "The Nordic QALY Shortfall Calculator is an interactive RShiny application developed to support health technology assessments (HTAs) across Denmark, Finland, Iceland, Norway, and Sweden. It estimates Quality-Adjusted Life Year (QALY) shortfalls—a key metric for evaluating disease severity and guiding healthcare prioritization. By comparing the quality-adjusted life expectancy (QALE) of individuals with a specific disease to that of the general population, the tool provides transparent, evidence-based insights using national life tables and health-related quality of life (HRQoL) data.\nThis project transforms static health economic evaluations into a dynamic, user-driven experience. Built entirely in RShiny, the app integrates validated utility scoring algorithms (e.g., EQ-5D-3L/5L) and applies the Sullivan method to calculate QALE and shortfall metrics. Users can input demographic and clinical parameters, select utility scenarios, and instantly visualize results. The app’s modular design supports flexible scenario comparisons, enabling rapid exploration of severity-based modifiers and their impact on HTA decisions.\nBy making QALY shortfall estimation accessible and interactive, the Nordic QALY Shortfall Calculator empowers researchers, policymakers, and HTA professionals to apply severity-based weighting in a consistent and transparent manner. It facilitates cross-country comparisons, supports methodological harmonization, and encourages data-driven decision-making. The app’s open and adaptable framework also allows for future updates and extensions, making it a valuable resource for ongoing research and policy development in the Nordic region and beyond.\nThe app is built using the Shiny package for R. It includes several visualizations and filters created using the following packages: DT, shiny, shinyWidgets, shinythemes, shinyjs, bslib, bsicons, lubridate, leaflet, highcharter. Try the app🔗\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/nsc.html#qaly-shortfall-calculator-for-nordics",
    "href": "projects/nsc.html#qaly-shortfall-calculator-for-nordics",
    "title": "MSA",
    "section": "",
    "text": "The Nordic Shortfall Calculator is a web application that allows users to explore and analyze the QALY shortfall based on updated utility values as well as compare them to previous values or even values used by other Nordic countries.\nThe app is built using the Shiny package for R. It includes several visualizations and filters created using the following packages: DT, shiny, shinyWidgets, shinythemes, shinyjs, bslib, bsicons, lubridate, leaflet, highcharter…. Check out the shiny app"
  },
  {
    "objectID": "projects/moonr.html",
    "href": "projects/moonr.html",
    "title": "Packaging MOON in R",
    "section": "",
    "text": "The MOON (Modeling Obesity in Norway) study is a comprehensive decision-analytic model designed to simulate the long-term health and economic impacts of obesity in the Norwegian population. Built using a Markov framework, the model tracks individuals from age 2 to 100 across health states—normal weight, overweight, obese grade 1, obese grade 2, and death—based on real-world longitudinal data from national health surveys and registries. It estimates prevalence, healthcare costs, and years of life lost due to obesity, providing a robust foundation for evaluating the cost-effectiveness of preventive and treatment interventions.\n\n\nWe are currently undertaking a modernization of the MOON model by transitioning it from its original Excel-based implementation to a more scalable and transparent R-based framework. This shift will involve re-coding the model logic, integrating statistical analyses directly within R, and improving the reproducibility and flexibility of simulations. By leveraging R’s capabilities in data handling, visualization, and probabilistic modeling, we aim to enhance the model’s usability for researchers, policymakers, and public health analysts.\nMigrating the MOON model to R will significantly improve its accessibility, adaptability, and analytical power. The new version will allow for easier updates with new data, more sophisticated scenario analyses, and integration with other public health datasets. It will also enable other researchers—both within and outside Norway—to replicate, calibrate, and extend the model to their own contexts. Ultimately, this upgrade will support more informed decision-making in obesity prevention and treatment, helping stakeholders evaluate long-term health and economic outcomes with greater precision.\n\n\n\n Back to top"
  },
  {
    "objectID": "projects/moonr.html#packaging-moon",
    "href": "projects/moonr.html#packaging-moon",
    "title": "MSA",
    "section": "",
    "text": "Both R and Excel are powerful data science tools and can be used to accomplish end-to-end analytics projects.\nGudrun and I, are trying to move the decision analytics model built on excel to R, to promote open-access science. The decision analytics model runs a Markov model to assess the cost effectiveness of intervention for obesity."
  },
  {
    "objectID": "resume.html#summary",
    "href": "resume.html#summary",
    "title": "Curriculum Vitae",
    "section": "Summary",
    "text": "Summary\n\nPhD in Genetic Epidemiology, dual master’s in Biostatistics, and bachelor’s in Statistics.\nSix years of experience in data analysis in various statistical methods and datasets related to health.\nKnowledge of methods related to epidemiology, biostatistics, clinical trials, and genetics with hands-on experience of its implementation in both R and Excel.\nTechnically minded with the ability to break down a complex solution to ensure understanding at multiple levels and heterogeneous audience.\nCollaborative and supportive team player, conscious of my role as a contributor to a good working environment.\nAbility to take on new challenges in a fast-paced environment and make decisions under pressure.\nFluent in English and beginner in Norwegian"
  },
  {
    "objectID": "resume.html#professional-experience",
    "href": "resume.html#professional-experience",
    "title": "Curriculum Vitae",
    "section": "Professional Experience",
    "text": "Professional Experience\n\nAssociate, Parexel - Remote, India\nJuly 2021 – February 2022\n\nSupported the development of interactive platforms (e.g., RShiny) to conduct economic evaluations (e.g., cost-effectiveness, budget impact) under senior guidance.\nPerformed statistical analyzes (e.g., Bayesian network meta-analysis, MAIC, STC) aligned with health technology assessment (HTA) guidelines (e.g., TSD, NICE) across multiple disease areas.\nAutomated dashboards (Excel/VBA) to visualize key clinical endpoints (e.g. survival curves, demographics) for regional stakeholder reporting.\nSupported client engagements by helping to coordinate projects, manage their expectations, and ensured the timely delivery of analytical output.\nContributed to statistical analysis plans (SAPs) by programming scripts, conducting feasibility assessments, and validating data sets for accuracy.\nAssisted in presenting analytical results to internal and external stakeholders, incorporating feedback to refine deliverables."
  },
  {
    "objectID": "resume.html#research-experience",
    "href": "resume.html#research-experience",
    "title": "Curriculum Vitae",
    "section": "Research Experience",
    "text": "Research Experience\n\nPhD, NTNU – Trondheim, Norway\nApril 2022 – Current\n\nApplied advanced statistical methods to analyze high-dimensional genetic and real-world registry data, generating actionable insights for large-scale studies.\nDesigned and optimized analysis pipelines, reducing computational time and resource usage, and increasing team productivity.\nPresented research findings at national and international conferences and published results in peer-reviewed journals, contributing to scientific knowledge and visibility.\nFostered and expanded collaborations with external university research groups, driving successful joint projects.\nBuilt a supportive academic network during an international research stay, facilitating new research opportunities.\nSecured more than 150,000 NOK in competitive external funding from three agencies, supporting innovative research initiatives."
  },
  {
    "objectID": "resume.html#project",
    "href": "resume.html#project",
    "title": "Curriculum Vitae",
    "section": "Project",
    "text": "Project\n\nNordic Shortfall Calculator\n\nDeveloped a proof-of-concept model that calculates the absolute and proportional shortfall of 4 Nordic countries, i.e., Denmark, Finland, Norway, and Sweden\nProvides up-to-date estimates of quality-adjusted life expectency of respective Nordic population based on the EQ-5D or 3D values.\nFeatures comparative options between different value sets for each country, discount rates, updates automatically with dynamic input, provides HRQoL, Cummulative Survival and Cummulative QALYs."
  },
  {
    "objectID": "resume.html#skills",
    "href": "resume.html#skills",
    "title": "Curriculum Vitae",
    "section": "Skills",
    "text": "Skills\n\nSoftware: R, SAS, Python, Git, Microsoft Excel, PowerPoint, Word\nTransferable: Communicator, Detail-oriented, Problem solver, Relationship builder, Results-driven, Strategic\nHobbies: Hiking, Skiing, Swimming, Anime"
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Curriculum Vitae",
    "section": "Education",
    "text": "Education\n\nMPhil in Biostatistics and Demography, International Institute for Population Sciences (2020 – 2021)\nMSc in Biostatistics and Demography, International Institute for Population Sciences (2018 – 2020)\nBSc in Statistics, University of Calcutta (2014 – 2018)"
  },
  {
    "objectID": "resume.html#publications",
    "href": "resume.html#publications",
    "title": "Curriculum Vitae",
    "section": "Publications",
    "text": "Publications\n\nPopulation screening of adults identifies novel genetic variants associated with celiac disease. Alam MS, Thomas L, Brumpton B, Hveem K, Lundin KE, Withoff S, Jonkers IH, Sollid LM, Hjort R, Ness-Jensen E. Scientific Reports. 2025 Jun 5;15(1):19764\nUnderstanding the spatial predictors of malnutrition among 0–2 years children in India using path analysis. Singh M, Alam MS, Majumdar P, Tiwary B, Narzari H, Mahendradhata Y. Frontiers in Public Health. 2021 Jul 30;9:667502\nThyroid Function Test in COVID-19 Patients: A Cross-Sectional Study in a Tertiary Care Hospital. Sen K, Sinha A, Sen S, Chakraborty S, Alam MS. Indian J Endocrinol Metab. 2020;24(6):532-536\nThe effects of social media consumption among the internet users during COVID-19 lockdown in India: Results from an online survey. Mustafa A, Alam MS, Shekhar C. Online Journal of Health and Allied Sciences 19 (4)"
  },
  {
    "objectID": "resume.html#conferences",
    "href": "resume.html#conferences",
    "title": "Curriculum Vitae",
    "section": "Conferences",
    "text": "Conferences\n\nOral\n\n20th International Celiac Disease Symposium – Sheffield, UK, September 2024\nNordic Conference on Future Health – Trondheim, Norway, September 2024\n16th International Conference on Urban Health – Xiamen, China, November 2019\n5th International Integrative Research Conference on Governance and Modernization in Changing Environment - Comilla, Bangladesh, December 2018\n\n\n\nPoster\n\n20th International Celiac Disease Symposium – Sheffield, UK, September 2024\nNordic Conference on Future Health – Trondheim, Norway, September 2024"
  },
  {
    "objectID": "resume.html#references",
    "href": "resume.html#references",
    "title": "Curriculum Vitae",
    "section": "References",
    "text": "References\nAvailable upon request."
  },
  {
    "objectID": "talks/iircgmce2019oral.html",
    "href": "talks/iircgmce2019oral.html",
    "title": "Shifting Paradigm in the Cause of Maternal Mortality in West Bengal: A Facility and Community-Based Mixed Method Approach Study",
    "section": "",
    "text": "5th International Integrative Research Conference on Governance and Modernization in Changing Environment (INSEARCH 2018)"
  },
  {
    "objectID": "talks/iircgmce2019oral.html#th-international-integrative-research-conference-on",
    "href": "talks/iircgmce2019oral.html#th-international-integrative-research-conference-on",
    "title": "Shifting Paradigm in the Cause of Maternal Mortality in West Bengal: A Facility and Community-Based Mixed Method Approach Study",
    "section": "",
    "text": "Governance and Modernization in Changing Environment (INSEARCH 2018)\nVenue: BARD, Comilla, Bangladesh\nBackground: Previously, studies have manifested a high magnitude of maternal deathsattributed to obstetric haemorrhage in West Bengal. But in the recent decade, the State has marked a unique recognition for having the highest maternal mortality caused by eclampsia in the country as well as in the globe.\nObjectives: The study aimed to determine the incidence of maternal mortality attributed to eclampsia and identify the confounding factors associated with eclamptic maternal deaths.\nMethods: It was a mixed method study. First, a facility-based study was conducted for all maternal deaths occurred between November 2013 and October 2015 (N=317), in two tertiary level hospitals. Second, we conducted community-based maternal death reviews (verbal autopsies) of 20 deaths.\nResults: Eclampsia accounted in one-third of maternal deaths. Almost two-thirds of maternal deaths attributed to eclampsia were highly concentrated among women who resided in distant areas from the studied hospitals. The women belonged to &lt;24 years age group (65%) and primigravidas (40%) mothers were noted to have an increased risk of eclamptic deaths as compared to relatively older groups and multigravida women. The maternal deaths related to eclampsia was comparatively higher among cesarean section experienced mother compared to normally delivered. Verbal autopsies indicated that majority of pregnant women had the irregular AN Cheek-ups history, particularly during the second trimester of pregnancy. Most of the eclamptic deceased women had been taken to at least three health facilities. Gravidity, the number of ANC and mode of delivery were the significant confounder of eclamptic deaths in the study.\nConclusion: The study confirmed an excess risk of hypertensive disorders which is much higher compared to previous studies in the globe. Establishment of separate Eclampsia Units at lower levels health facilities equipping with modern ICU facilities is more plausible and expedient pathway to alleviate the burden of eclampsia-related maternal deaths.\nKeywords: Eclampsia, Maternal Mortality, West Bengal"
  },
  {
    "objectID": "talks/iircgmce2019oral.html#th-international-integrative-research-conference-on-governance-and-modernization-in-changing-environment-insearch-2018",
    "href": "talks/iircgmce2019oral.html#th-international-integrative-research-conference-on-governance-and-modernization-in-changing-environment-insearch-2018",
    "title": "Shifting Paradigm in the Cause of Maternal Mortality in West Bengal: A Facility and Community-Based Mixed Method Approach Study",
    "section": "",
    "text": "Venue: BARD, Comilla, Bangladesh"
  },
  {
    "objectID": "talks/iircgmce2019oral.html#abstract",
    "href": "talks/iircgmce2019oral.html#abstract",
    "title": "Shifting Paradigm in the Cause of Maternal Mortality in West Bengal: A Facility and Community-Based Mixed Method Approach Study",
    "section": "Abstract",
    "text": "Abstract\nBackground: Previously, studies have manifested a high magnitude of maternal deathsattributed to obstetric haemorrhage in West Bengal. But in the recent decade, the State has marked a unique recognition for having the highest maternal mortality caused by eclampsia in the country as well as in the globe.\nObjectives: The study aimed to determine the incidence of maternal mortality attributed to eclampsia and identify the confounding factors associated with eclamptic maternal deaths.\nMethods: It was a mixed method study. First, a facility-based study was conducted for all maternal deaths occurred between November 2013 and October 2015 (N=317), in two tertiary level hospitals. Second, we conducted community-based maternal death reviews (verbal autopsies) of 20 deaths.\nResults: Eclampsia accounted in one-third of maternal deaths. Almost two-thirds of maternal deaths attributed to eclampsia were highly concentrated among women who resided in distant areas from the studied hospitals. The women belonged to &lt;24 years age group (65%) and primigravidas (40%) mothers were noted to have an increased risk of eclamptic deaths as compared to relatively older groups and multigravida women. The maternal deaths related to eclampsia was comparatively higher among cesarean section experienced mother compared to normally delivered. Verbal autopsies indicated that majority of pregnant women had the irregular AN Cheek-ups history, particularly during the second trimester of pregnancy. Most of the eclamptic deceased women had been taken to at least three health facilities. Gravidity, the number of ANC and mode of delivery were the significant confounder of eclamptic deaths in the study.\nConclusion: The study confirmed an excess risk of hypertensive disorders which is much higher compared to previous studies in the globe. Establishment of separate Eclampsia Units at lower levels health facilities equipping with modern ICU facilities is more plausible and expedient pathway to alleviate the burden of eclampsia-related maternal deaths.\nKeywords: Eclampsia, Maternal Mortality, West Bengal"
  },
  {
    "objectID": "talks/iircgmce2019oral.html#conference-name",
    "href": "talks/iircgmce2019oral.html#conference-name",
    "title": "Shifting Paradigm in the Cause of Maternal Mortality in West Bengal: A Facility and Community-Based Mixed Method Approach Study",
    "section": "",
    "text": "5th International Integrative Research Conference on Governance and Modernization in Changing Environment (INSEARCH 2018)"
  },
  {
    "objectID": "talks/iircgmce2019oral.html#conference-venue",
    "href": "talks/iircgmce2019oral.html#conference-venue",
    "title": "Shifting Paradigm in the Cause of Maternal Mortality in West Bengal: A Facility and Community-Based Mixed Method Approach Study",
    "section": "Conference Venue:",
    "text": "Conference Venue:\nBARD, Comilla, Bangladesh"
  },
  {
    "objectID": "talks/insearch2018oral.html#conference-venue",
    "href": "talks/insearch2018oral.html#conference-venue",
    "title": "Shifting Paradigm in the Cause of Maternal Mortality in West Bengal: A Facility and Community-Based Mixed Method Approach Study",
    "section": "Conference Venue:",
    "text": "Conference Venue:\nBARD, Comilla, Bangladesh"
  },
  {
    "objectID": "talks/insearch2018oral.html#abstract",
    "href": "talks/insearch2018oral.html#abstract",
    "title": "Shifting Paradigm in the Cause of Maternal Mortality in West Bengal: A Facility and Community-Based Mixed Method Approach Study",
    "section": "Abstract",
    "text": "Abstract\nBackground: Previously, studies have manifested a high magnitude of maternal deathsattributed to obstetric haemorrhage in West Bengal. But in the recent decade, the State has marked a unique recognition for having the highest maternal mortality caused by eclampsia in the country as well as in the globe.\nObjectives: The study aimed to determine the incidence of maternal mortality attributed to eclampsia and identify the confounding factors associated with eclamptic maternal deaths.\nMethods: It was a mixed method study. First, a facility-based study was conducted for all maternal deaths occurred between November 2013 and October 2015 (N=317), in two tertiary level hospitals. Second, we conducted community-based maternal death reviews (verbal autopsies) of 20 deaths.\nResults: Eclampsia accounted in one-third of maternal deaths. Almost two-thirds of maternal deaths attributed to eclampsia were highly concentrated among women who resided in distant areas from the studied hospitals. The women belonged to &lt;24 years age group (65%) and primigravidas (40%) mothers were noted to have an increased risk of eclamptic deaths as compared to relatively older groups and multigravida women. The maternal deaths related to eclampsia was comparatively higher among cesarean section experienced mother compared to normally delivered. Verbal autopsies indicated that majority of pregnant women had the irregular AN Cheek-ups history, particularly during the second trimester of pregnancy. Most of the eclamptic deceased women had been taken to at least three health facilities. Gravidity, the number of ANC and mode of delivery were the significant confounder of eclamptic deaths in the study.\nConclusion: The study confirmed an excess risk of hypertensive disorders which is much higher compared to previous studies in the globe. Establishment of separate Eclampsia Units at lower levels health facilities equipping with modern ICU facilities is more plausible and expedient pathway to alleviate the burden of eclampsia-related maternal deaths.\nKeywords: Eclampsia, Maternal Mortality, West Bengal"
  },
  {
    "objectID": "talks/icuh2020oral.html#conference-venue",
    "href": "talks/icuh2020oral.html#conference-venue",
    "title": "Prevalence of communicable diseases and its epidemiological correlates in major urban populated states of India: Evidence from a nationally representative sample",
    "section": "Conference Venue:",
    "text": "Conference Venue:\nXiamen, China"
  },
  {
    "objectID": "talks/icuh2020oral.html#abstract",
    "href": "talks/icuh2020oral.html#abstract",
    "title": "Prevalence of communicable diseases and its epidemiological correlates in major urban populated states of India: Evidence from a nationally representative sample",
    "section": "Abstract",
    "text": "Abstract\nIntroduction: Poor water quality has been considered to be a confounder factor of the communicable disease. The study analyzed the current burden of communicable diseases and explored the factors associated with it in the major urban populated states of India.\nMethods: This study used the India’s fourth round District Level Household and Facility Survey (2012–13) data. The study particularly focused on the major urban states of India which are having more than 30,000 urban populations. We used bivariate analysis and the adjusted odds ratio (AOR) with 95% confidence intervals (CI) to identify the independent predictors.\nResults: Public tap was found to be a prime source of drinking water in the urban India. Tamil Nadu (near about half) had the largest urban population using unimproved water sources. The prevalence of communicable disease was high (11 percent) among the population using unimproved drinking compared to their counterparts (5 percent). About 15 percent of the urban population in West Bengal had higher communicable diseases than other urban populated states of India. The factors found significantly associated with communicable diseases were age (AOR=1.40), years of schooling (AOR=0.95), source of drinking water (AOR=0.77) and having toilet facility (AOR=1.32).\nConclusion: Improved drinking water coverage in India is still considerably low as compared to the national target set in SDG. The present study suggests that improved drinking water sources and clean and hygienic toilet facility are significant determinants of communicable diseases. The measure should be devised to enhance health information and accessibility of safe drinking water to prevent communicable diseases in line with achieving the Sustainable Development Goal 3.\nKeywords: Communicable diseases, risk factors, urban area, India."
  },
  {
    "objectID": "talks/icuh2019oral.html#conference-venue",
    "href": "talks/icuh2019oral.html#conference-venue",
    "title": "Prevalence of communicable diseases and its epidemiological correlates in major urban populated states of India: Evidence from a nationally representative sample",
    "section": "Conference Venue:",
    "text": "Conference Venue:\nXiamen, China"
  },
  {
    "objectID": "talks/icuh2019oral.html#abstract",
    "href": "talks/icuh2019oral.html#abstract",
    "title": "Prevalence of communicable diseases and its epidemiological correlates in major urban populated states of India: Evidence from a nationally representative sample",
    "section": "Abstract",
    "text": "Abstract\nIntroduction: Poor water quality has been considered to be a confounder factor of the communicable disease. The study analyzed the current burden of communicable diseases and explored the factors associated with it in the major urban populated states of India.\nMethods: This study used the India’s fourth round District Level Household and Facility Survey (2012–13) data. The study particularly focused on the major urban states of India which are having more than 30,000 urban populations. We used bivariate analysis and the adjusted odds ratio (AOR) with 95% confidence intervals (CI) to identify the independent predictors.\nResults: Public tap was found to be a prime source of drinking water in the urban India. Tamil Nadu (near about half) had the largest urban population using unimproved water sources. The prevalence of communicable disease was high (11 percent) among the population using unimproved drinking compared to their counterparts (5 percent). About 15 percent of the urban population in West Bengal had higher communicable diseases than other urban populated states of India. The factors found significantly associated with communicable diseases were age (AOR=1.40), years of schooling (AOR=0.95), source of drinking water (AOR=0.77) and having toilet facility (AOR=1.32).\nConclusion: Improved drinking water coverage in India is still considerably low as compared to the national target set in SDG. The present study suggests that improved drinking water sources and clean and hygienic toilet facility are significant determinants of communicable diseases. The measure should be devised to enhance health information and accessibility of safe drinking water to prevent communicable diseases in line with achieving the Sustainable Development Goal 3.\nKeywords: Communicable diseases, risk factors, urban area, India."
  },
  {
    "objectID": "talks/icds24poster.html#conference-venue",
    "href": "talks/icds24poster.html#conference-venue",
    "title": "Assessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.",
    "section": "Conference Venue:",
    "text": "Conference Venue:\nSheffield, UK"
  },
  {
    "objectID": "talks/icds24poster.html#abstract",
    "href": "talks/icds24poster.html#abstract",
    "title": "Assessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.",
    "section": "Abstract",
    "text": "Abstract\nIntroduction: Despite diagnostic advances in celiac disease (CeD), many patients remain undiagnosed. CeD has well established genetic risk factors in the leukocyte antigen (HLA) loci. The goal of the study was to provide susceptibility estimates for CeD subgroups using polygenic risk score (PRS) beyond the HLA loci.\nMethods: In the population-based HUNT study in Norway, 52,588 adults underwent CeD screening via serology with diagnosis confirmed by histology (revealing 465 incident [Marsh 3] and 230 potential [Marsh 1/2] cases). Additionally, 377 known CeD cases were identified from medical registries. We reproduced a previously published PRS of CeD (228 SNPs) using the PRS-cs tool. All analysis were adjusted for age, sex, genotyping batch and 20 principal components.\nResults: The PRS could effectively distinguish between incident and prevalent cases from controls, with area under receiver operating characteristic curves at 83.8% and 83.5%, respectively, superior to potential cases (68.8%). For every standard deviation increase in the PRS, the odds increased 3.4-times (95% confidence interval [CI] 3.1-3.8) for confirmed (incident and prevalent) and 1.8-times (CI 1.6-2.1) for potential cases. Individuals in the top vs remaining decile of the PRS had 8.4-times (CI 7.3-9.7) higher odds of CeD. The proportion of variation explained by the PRS was 20.9% (CI 17.2%-25.6%) from HLA and 1% (CI 0.2%-2.3%) from non-HLA.\nConclusions: Incorporating non-HLA variants slightly enhanced identification of CeD beyond HLA variants alone, highlighting the potential of genetic risk stratification, integrating both HLA and non-HLA variants to pinpoint high-risk individuals.\nKeywords: polygenic, symptoms, PRS, onset, genetic, autoimmune"
  },
  {
    "objectID": "talks/ncfh24poster.html#conference-venue",
    "href": "talks/ncfh24poster.html#conference-venue",
    "title": "The IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.",
    "section": "Conference Venue:",
    "text": "Conference Venue:\nTrondheim, Norway"
  },
  {
    "objectID": "talks/ncfh24poster.html#abstract",
    "href": "talks/ncfh24poster.html#abstract",
    "title": "The IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.",
    "section": "Abstract",
    "text": "Abstract\nIntroduction: Previous studies have discovered genetic loci associated with celiac disease (CeD), within both the human leukocyte antigen (HLA) and the non-HLA region. Yet, half of the genetic variation remains unexplained. This study aims to investigate novel associations with CeD taking advantage of a screened population and mitigating selection-bias from prior case-control studies.\nMethods: Utilizing data from the HUNT study in Norway, we screened 52,358 adults (&gt;20 years) for CeD using serology, identifying 465 incident biopsy-confirmed cases. Additionally, 377 prevalent cases were identified through hospital journal searches. Genotyping of 373,185 SNPs was performed using four Illumina HumanCoreExome arrays. Imputation using the Haplotype Reference Consortium panel, resulted in approximately 24.9 million variants, post quality control. A genome-wide association study was performed using SAIGE, and functional mapping and pathway enrichment analysis was conducted using FUMA.\nResults: Five novel SNPs out of 6 independent associations reached genome wide significance (\\(P≤5E-08\\)) having minor allele count greater than 10. EML6, BCL11A, ABCA12, LRFN2, MED13, IRX1 are the loci respectively. Around 50 of over 80 loci identified in previous GWASs were replicated in our data, with REL, ASHA2, IL18RAP, IL18R1, IL18RL1, IL18RL2, LPP, PFKFB3, PRKCQ, CIITA, SOCS1, and CLEC16A reaching suggestive significance levels (\\(5E-08≤P≤5E-06\\)).\nConclusion: The strongest evidence for an association was observed at IRX1, warranting further studies to validate this finding. Notably, the IRX1 loci has also been associated with other autoimmune diseases such as rheumatoid arthritis.\nKeywords: celiac, gluten, non-HLA, autoimmune, GWAS."
  },
  {
    "objectID": "talks/ncfh24oral.html#conference-venue",
    "href": "talks/ncfh24oral.html#conference-venue",
    "title": "Assessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.",
    "section": "Conference Venue:",
    "text": "Conference Venue:\nTrondheim, Norway"
  },
  {
    "objectID": "talks/ncfh24oral.html#abstract",
    "href": "talks/ncfh24oral.html#abstract",
    "title": "Assessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.",
    "section": "Abstract",
    "text": "Abstract\nIntroduction: Despite diagnostic advances in celiac disease (CeD), many patients remain undiagnosed. CeD has well established genetic risk factors in the leukocyte antigen (HLA) loci. The goal of the study was to provide susceptibility estimates for CeD subgroups using polygenic risk score (PRS) beyond the HLA loci.\nMethods: In the population-based HUNT study in Norway, 52,588 adults underwent CeD screening via serology with diagnosis confirmed by histology (revealing 465 incident [Marsh 3] and 230 potential [Marsh 1/2] cases). Additionally, 377 known CeD cases were identified from medical registries. We reproduced a previously published PRS of CeD (228 SNPs) using the PRS-cs tool. All analysis were adjusted for age, sex, genotyping batch and 20 principal components.\nResults: The PRS could effectively distinguish between incident and prevalent cases from controls, with area under receiver operating characteristic curves at 83.8% and 83.5%, respectively, superior to potential cases (68.8%). For every standard deviation increase in the PRS, the odds increased 3.4-times (95% confidence interval [CI] 3.1-3.8) for confirmed (incident and prevalent) and 1.8-times (CI 1.6-2.1) for potential cases. Individuals in the top vs remaining decile of the PRS had 8.4-times (CI 7.3-9.7) higher odds of CeD. The proportion of variation explained by the PRS was 20.9% (CI 17.2%-25.6%) from HLA and 1% (CI 0.2%-2.3%) from non-HLA.\nConclusions: Incorporating non-HLA variants slightly enhanced identification of CeD beyond HLA variants alone, highlighting the potential of genetic risk stratification, integrating both HLA and non-HLA variants to pinpoint high-risk individuals.\nKeywords: polygenic, symptoms, PRS, onset, genetic, autoimmune"
  },
  {
    "objectID": "talks/icds24oral.html#conference-venue",
    "href": "talks/icds24oral.html#conference-venue",
    "title": "The IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.",
    "section": "Conference Venue:",
    "text": "Conference Venue:\nSheffield, UK"
  },
  {
    "objectID": "talks/icds24oral.html#abstract",
    "href": "talks/icds24oral.html#abstract",
    "title": "The IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.",
    "section": "Abstract",
    "text": "Abstract\nIntroduction: Previous studies have discovered genetic loci associated with celiac disease (CeD), within both the human leukocyte antigen (HLA) and the non-HLA region. Yet, half of the genetic variation remains unexplained. This study aims to investigate novel associations with CeD taking advantage of a screened population and mitigating selection-bias from prior case-control studies.\nMethods: Utilizing data from the HUNT study in Norway, we screened 52,358 adults (&gt;20 years) for CeD using serology, identifying 465 incident biopsy-confirmed cases. Additionally, 377 prevalent cases were identified through hospital journal searches. Genotyping of 373,185 SNPs was performed using four Illumina HumanCoreExome arrays. Imputation using the Haplotype Reference Consortium panel, resulted in approximately 24.9 million variants, post quality control. A genome-wide association study was performed using SAIGE, and functional mapping and pathway enrichment analysis was conducted using FUMA.\nResults: Five novel SNPs out of 6 independent associations reached genome wide significance (\\(P≤5E-08\\)) having minor allele count greater than 10. EML6, BCL11A, ABCA12, LRFN2, MED13, IRX1 are the loci respectively. Around 50 of over 80 loci identified in previous GWASs were replicated in our data, with REL, ASHA2, IL18RAP, IL18R1, IL18RL1, IL18RL2, LPP, PFKFB3, PRKCQ, CIITA, SOCS1, and CLEC16A reaching suggestive significance levels (\\(5E-08≤P≤5E-06\\)).\nConclusion: The strongest evidence for an association was observed at IRX1, warranting further studies to validate this finding. Notably, the IRX1 loci has also been associated with other autoimmune diseases such as rheumatoid arthritis.\nKeywords: celiac, gluten, non-HLA, autoimmune, GWAS."
  },
  {
    "objectID": "talks/icds24oral.html",
    "href": "talks/icds24oral.html",
    "title": "The IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.",
    "section": "",
    "text": "View presentation"
  },
  {
    "objectID": "talks/icds24oral.html#conference-name",
    "href": "talks/icds24oral.html#conference-name",
    "title": "The IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.",
    "section": "Conference name",
    "text": "Conference name\n\nInternational Coeliac Disease Symposium (ICDS)"
  },
  {
    "objectID": "talks/ncfh24poster.html",
    "href": "talks/ncfh24poster.html",
    "title": "The IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.",
    "section": "",
    "text": "View poster"
  },
  {
    "objectID": "talks/ncfh24poster.html#conference-name",
    "href": "talks/ncfh24poster.html#conference-name",
    "title": "The IRX1 locus is associated with celiac disease: results from a screened population-based cohort, the HUNT study.",
    "section": "Conference name",
    "text": "Conference name\n\nThe Nordic Conference on Future Health"
  },
  {
    "objectID": "talks/ncfh24oral.html",
    "href": "talks/ncfh24oral.html",
    "title": "Assessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.",
    "section": "",
    "text": "View presentation"
  },
  {
    "objectID": "talks/ncfh24oral.html#conference-name",
    "href": "talks/ncfh24oral.html#conference-name",
    "title": "Assessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.",
    "section": "Conference name",
    "text": "Conference name\n\nThe Nordic Conference on Future Health"
  },
  {
    "objectID": "talks/icds24poster.html",
    "href": "talks/icds24poster.html",
    "title": "Assessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.",
    "section": "",
    "text": "View poster"
  },
  {
    "objectID": "talks/icds24poster.html#conference-name",
    "href": "talks/icds24poster.html#conference-name",
    "title": "Assessing the susceptibility of celiac disease by polygenic risk scores: analysis of a population-based cohort, the HUNT study.",
    "section": "Conference name",
    "text": "Conference name\n\nInternational Coeliac Disease Symposium (ICDS)"
  },
  {
    "objectID": "blogs/mice.html",
    "href": "blogs/mice.html",
    "title": "From Missing to Meaningful: Beginner’s Guide to Multiple Imputation",
    "section": "",
    "text": "Missing data is a common issue in real-world datasets. Ignoring or improperly handling missing values can lead to biased results and incorrect conclusions. One powerful technique to address this is Multiple Imputation, and in R, the mice package makes it accessible and effective.\nThis post will walk you through:\n\nWhat Multiple Imputation is\nWhy it’s useful\nHow to use the mice package in R\nDifferent imputation methods and their assumptions\nLimitations of Multiple Imputation"
  },
  {
    "objectID": "blogs/mice.html#introduction",
    "href": "blogs/mice.html#introduction",
    "title": "From Missing to Meaningful: Beginner’s Guide to Multiple Imputation",
    "section": "",
    "text": "Missing data is a common issue in real-world datasets. Ignoring or improperly handling missing values can lead to biased results and incorrect conclusions. One powerful technique to address this is Multiple Imputation, and in R, the mice package makes it accessible and effective.\nThis post will walk you through:\n\nWhat Multiple Imputation is\nWhy it’s useful\nHow to use the mice package in R\nDifferent imputation methods and their assumptions\nLimitations of Multiple Imputation"
  },
  {
    "objectID": "blogs/mice.html#what-is-multiple-imputation",
    "href": "blogs/mice.html#what-is-multiple-imputation",
    "title": "From Missing to Meaningful: Beginner’s Guide to Multiple Imputation",
    "section": "What is Multiple Imputation?",
    "text": "What is Multiple Imputation?\nMultiple Imputation is a statistical technique where missing values are filled in multiple times to create several complete datasets. Each dataset is analyzed separately, and the results are combined to account for the uncertainty due to missing data."
  },
  {
    "objectID": "blogs/mice.html#why-use-multiple-imputation",
    "href": "blogs/mice.html#why-use-multiple-imputation",
    "title": "From Missing to Meaningful: Beginner’s Guide to Multiple Imputation",
    "section": "Why Use Multiple Imputation?",
    "text": "Why Use Multiple Imputation?\n\nPreserves sample size\nReduces bias compared to single imputation\nAccounts for uncertainty in missing data\nWorks well with many types of data"
  },
  {
    "objectID": "blogs/mice.html#getting-started-with-mice-in-r",
    "href": "blogs/mice.html#getting-started-with-mice-in-r",
    "title": "From Missing to Meaningful: Beginner’s Guide to Multiple Imputation",
    "section": "Getting Started with mice in R",
    "text": "Getting Started with mice in R\n0. Install and Load the Package\n\nCode# install.packages(\"mice\")\n# install.packages(\"gt\")\nlibrary(mice)\nlibrary(gt)\n# example dataset: airquality\ndata(\"airquality\")\nhead(airquality)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\nCodesummary(airquality)\n\n     Ozone           Solar.R           Wind             Temp      \n Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  \n 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  \n Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  \n Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  \n 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  \n Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  \n NA's   :37       NA's   :7                                       \n     Month            Day      \n Min.   :5.000   Min.   : 1.0  \n 1st Qu.:6.000   1st Qu.: 8.0  \n Median :7.000   Median :16.0  \n Mean   :6.993   Mean   :15.8  \n 3rd Qu.:8.000   3rd Qu.:23.0  \n Max.   :9.000   Max.   :31.0  \n                               \n\n\nThis dataset contains missing values in Ozone and Solar.R.\n1. Check missing data pattern\n\nCodemd.pattern(airquality)\n\n\n\n\n\n\n\n    Wind Temp Month Day Solar.R Ozone   \n111    1    1     1   1       1     1  0\n35     1    1     1   1       1     0  1\n5      1    1     1   1       0     1  1\n2      1    1     1   1       0     0  2\n       0    0     0   0       7    37 44\n\n\n2. Perform imputations\n\nCodeimp &lt;- mice(airquality, m = 5, method = 'pmm', seed = 123)\n\n\n iter imp variable\n  1   1  Ozone  Solar.R\n  1   2  Ozone  Solar.R\n  1   3  Ozone  Solar.R\n  1   4  Ozone  Solar.R\n  1   5  Ozone  Solar.R\n  2   1  Ozone  Solar.R\n  2   2  Ozone  Solar.R\n  2   3  Ozone  Solar.R\n  2   4  Ozone  Solar.R\n  2   5  Ozone  Solar.R\n  3   1  Ozone  Solar.R\n  3   2  Ozone  Solar.R\n  3   3  Ozone  Solar.R\n  3   4  Ozone  Solar.R\n  3   5  Ozone  Solar.R\n  4   1  Ozone  Solar.R\n  4   2  Ozone  Solar.R\n  4   3  Ozone  Solar.R\n  4   4  Ozone  Solar.R\n  4   5  Ozone  Solar.R\n  5   1  Ozone  Solar.R\n  5   2  Ozone  Solar.R\n  5   3  Ozone  Solar.R\n  5   4  Ozone  Solar.R\n  5   5  Ozone  Solar.R\n\n\nm = 5: Number of imputed datasets\nmethod = 'pmm': Predictive Mean Matching (default for numeric data)\n\nImputation methods within mice()\n\n\nMethod\nDescription\nAssumptions\n\n\n\npmm\nPredictive Mean\nMatching Data is approximately normal\n\n\nnorm\nBayesian linear regression\nContinuous data\n\n\nlogreg\nLogistic regression\nBinary data\n\n\npolyreg\nPolytomous regression\nCategorical data\n\n\ncart\nClassification and regression trees\nNon-parametric\n\n\n3. Check imputed values\n\nCodeimp$imp$Ozone\n\n      1   2   3   4   5\n5    18   1  37  18  32\n10   12  30  30  20  20\n25   18   8   8  28   6\n26   13  18  18  20  13\n27   20  11  21  32  20\n32   16  23  44  49  59\n33   12   7  18  39  59\n34   19  37  28  18  32\n35   52  39  20  59  96\n36    7  85  71  96  80\n37   21  18  24  29  31\n39   64  76  61  76  76\n42   64  76 115  97 122\n43   61  97  80  76  97\n45   30  29  31  35  28\n46   13  63  52  37  63\n52   23  71  23  35  23\n53   85  64  64  40 108\n54   37  59  47  20  49\n55   23  37  71  35  89\n56   29  29  28  44  46\n57   47  23  35  40  63\n58   44  23  22  23  23\n59   46  45  36  20  28\n60   11  34   9  41   7\n61   78  64  78  73 108\n65   18  20  36  16  32\n72   52  35  16  44  35\n75   40  96  46  61  37\n83    7  59  35  71  23\n84   29  63  20  89  40\n102 110  77 108  66  82\n103  28  40  13  52  35\n107  16  16  14  21  23\n115  22  23  23  16  24\n119 122 122  85 135  82\n150  27  44  14  12  13\n\n\n4. Complete the data\n\nCodecompleted_data &lt;- complete(imp, 1)  # Get the first imputed dataset\nhead(completed_data)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    18     150 14.3   56     5   5\n6    28      48 14.9   66     5   6\n\n\n4. Analyze and pool the results\n\nCodefit &lt;- with(data = imp, exp = lm(Ozone ~ Solar.R + Wind + Temp))\npooled &lt;- pool(fit)\n\npooled_summary &lt;- summary(pooled)\n\n# Remove the 'statistic' and 'df' column\npooled_summary &lt;- pooled_summary[, !(names(pooled_summary) %in% c(\"statistic\", \"df\"))]\n\n# Create a gt table\ngt_table &lt;- pooled_summary |&gt;\n  gt() |&gt;\n  tab_header(\n    title = \"Pooled Regression Results\",\n    subtitle = \"Using Multiple Imputation with mice\"\n  ) |&gt;\n  fmt_number(\n    columns = vars(estimate, std.error, p.value),\n    decimals = 3\n  ) |&gt;\n  cols_label(\n    term = \"Term\",\n    estimate = \"Estimate\",\n    std.error = \"Std. Error\",\n    p.value = \"p-Value\"\n  )\n\ngt_table\n\n\n\n\n\n\nPooled Regression Results\n\n\nUsing Multiple Imputation with mice\n\n\nTerm\nEstimate\nStd. Error\np-Value\n\n\n\n\n(Intercept)\n−62.907\n22.861\n0.009\n\n\nSolar.R\n0.053\n0.026\n0.059\n\n\nWind\n−3.075\n0.655\n0.000\n\n\nTemp\n1.618\n0.241\n0.000"
  },
  {
    "objectID": "blogs/mice.html#step-by-step-imputation",
    "href": "blogs/mice.html#step-by-step-imputation",
    "title": "Beginner’s Guide to Multiple Imputation Using the mice Package in R",
    "section": "Step-by-step imputation",
    "text": "Step-by-step imputation\n\n1. Check missing data pattern\nmd.pattern(airquality)\n\n\n2. Perform imputations\nimp &lt;- mice(airquality, m = 5, method = 'pmm', seed = 123)\nm = 5: Number of imputed datasets\nmethod = 'pmm': Predictive Mean Matching (default for numeric data)\nImputation methods in mice()\n\n\n3. Check imputed values\nimp$imp$Ozone\n\n\n4. Complete the data\ncompleted_data &lt;- complete(imp, 1)  # Get the first imputed dataset\nhead(completed_data)\n\n\n4. Analyze and pool the results\nfit &lt;- with(data = imp, exp = lm(Ozone ~ Solar.R + Wind + Temp))\npooled &lt;- pool(fit)\nsummary(pooled)\n\n\nLimitations of Multiple Imputation\n\nComputationally intensive\nRequires careful model specification\nAssumes data is Missing at Random (MAR) — not always true\nCan be complex for high-dimensional data\n\n\n\nConclusion\nMultiple Imputation is a robust way to handle missing data, and the mice package in R makes it approachable even for beginners. By understanding the methodology and using appropriate imputation methods, you can improve the quality of your analyses significantly.\n\n\n🧵 TL;DR: Multiple Imputation with mice in R\n\nProblem: Missing data can bias results and reduce statistical power.\nSolution: Multiple Imputation fills in missing values multiple times to reflect uncertainty.\nTool: The mice package in R makes this easy and flexible.\nSteps:\n\nInspect missing data (md.pattern)\nImpute with mice() using methods like pmm, norm, cart, etc.\nAnalyze each imputed dataset\nPool results for final inference\nUse Cases: Surveys, clinical trials, social science data, etc.\n\nAssumptions: Data is Missing at Random (MAR)\nLimitations: Computational cost, model sensitivity, assumption of MAR"
  },
  {
    "objectID": "blogs/mice.html#limitations-of-multiple-imputation",
    "href": "blogs/mice.html#limitations-of-multiple-imputation",
    "title": "From Missing to Meaningful: Beginner’s Guide to Multiple Imputation",
    "section": "Limitations of Multiple Imputation",
    "text": "Limitations of Multiple Imputation\n\nComputationally intensive\nRequires careful model specification\nAssumes data is Missing at Random (MAR) — not always true\nCan be complex for high-dimensional data"
  },
  {
    "objectID": "blogs/mice.html#conclusion",
    "href": "blogs/mice.html#conclusion",
    "title": "From Missing to Meaningful: Beginner’s Guide to Multiple Imputation",
    "section": "Conclusion",
    "text": "Conclusion\nMultiple Imputation is a robust way to handle missing data, and the mice package in R makes it approachable even for beginners. By understanding the methodology and using appropriate imputation methods, you can improve the quality of your analyses significantly."
  },
  {
    "objectID": "blogs/mice.html#tldr-multiple-imputation-with-mice-in-r",
    "href": "blogs/mice.html#tldr-multiple-imputation-with-mice-in-r",
    "title": "From Missing to Meaningful: Beginner’s Guide to Multiple Imputation",
    "section": "🧵 TL;DR: Multiple Imputation with mice in R",
    "text": "🧵 TL;DR: Multiple Imputation with mice in R\n\nProblem: Missing data can bias results and reduce statistical power.\nSolution: Multiple Imputation fills in missing values multiple times to reflect uncertainty.\nTool: The mice package in R makes this easy and flexible.\nSteps:\n\nInspect missing data (md.pattern)\nImpute with mice() using methods like pmm, norm, cart, etc.\nAnalyze each imputed dataset\nPool results for final inference\nUse Cases: Surveys, clinical trials, social science data, etc.\n\n\nAssumptions: Data is Missing at Random (MAR)\nLimitations: Computational cost, model sensitivity, assumption of MAR"
  },
  {
    "objectID": "blogs/gitsetup.html#what-youll-learn",
    "href": "blogs/gitsetup.html#what-youll-learn",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "",
    "text": "Whether you’re a beginner developer or switching to a new machine, setting up Git with SSH authentication can seem daunting. This comprehensive guide will walk you through every step to get you from a fresh installation to pushing your first commit securely.\nBy the end of this guide, you’ll be able to: - Configure Git with your identity - Generate and set up SSH keys for secure authentication - Create and manage local Git repositories - Connect your local work to remote repositories (GitHub, GitLab, etc.) - Understand the basic Git workflow for daily development"
  },
  {
    "objectID": "blogs/gitsetup.html#prerequisites",
    "href": "blogs/gitsetup.html#prerequisites",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nA computer with terminal/command line access\nAn account on a Git hosting service (GitHub, GitLab, Bitbucket, etc.)\nBasic familiarity with command line operations"
  },
  {
    "objectID": "blogs/gitsetup.html#step-1-install-and-configure-git",
    "href": "blogs/gitsetup.html#step-1-install-and-configure-git",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Step 1: Install and Configure Git",
    "text": "Step 1: Install and Configure Git\n\nInstall Git\nIf you haven’t already, download and install Git from the official website. Most Linux distributions and macOS come with Git pre-installed, but it’s worth updating to the latest version.\nCheck if Git is installed:\ngit --version\n\n\nConfigure Your Git Identity\nThis is crucial - Git needs to know who you are for commit attribution:\ngit config --global user.name \"Your Full Name\"\ngit config --global user.email \"your.email@example.com\"\nPro tip: Use the same email address associated with your GitHub/GitLab account for seamless integration.\nVerify your configuration:\ngit config --global --list\n\n\nOptional: Set Your Default Editor\nConfigure your preferred text editor for commit messages:\n# For VS Code\ngit config --global core.editor \"code --wait\"\n\n# For nano (beginner-friendly)\ngit config --global core.editor \"nano\"\n\n# For vim\ngit config --global core.editor \"vim\""
  },
  {
    "objectID": "blogs/gitsetup.html#step-2-set-up-ssh-keys-for-secure-authentication",
    "href": "blogs/gitsetup.html#step-2-set-up-ssh-keys-for-secure-authentication",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Step 2: Set Up SSH Keys for Secure Authentication",
    "text": "Step 2: Set Up SSH Keys for Secure Authentication\nSSH keys provide a secure way to authenticate with Git hosting services without entering your password every time.\n\nGenerate Your SSH Key\nCreate a new SSH key pair using the modern Ed25519 algorithm:\nssh-keygen -t ed25519 -C \"your.email@example.com\"\nWhen prompted: - File location: Press Enter to accept the default (~/.ssh/id_ed25519) - Passphrase: Optional but recommended for extra security\n\n\nStart the SSH Agent\nThe SSH agent manages your keys in memory:\neval \"$(ssh-agent -s)\"\nYou should see output like: Agent pid 12345\n\n\nAdd Your Key to the SSH Agent\nssh-add ~/.ssh/id_ed25519\nIf you set a passphrase, you’ll be prompted to enter it.\n\n\nCopy Your Public Key\nDisplay and copy your public key:\ncat ~/.ssh/id_ed25519.pub\nCopy the entire output (starts with ssh-ed25519 and ends with your email).\n\n\nAdd Key to Your Git Hosting Service\n\nFor GitHub:\n\nGo to Settings → SSH and GPG keys\nClick New SSH key\nGive it a descriptive title (e.g., “My Laptop”)\nPaste your public key\nClick Add SSH key\n\n\n\nFor GitLab:\n\nGo to Preferences → SSH Keys\nPaste your public key in the Key field\nAdd a title and expiration date (optional)\nClick Add key\n\n\n\n\nTest Your SSH Connection\nVerify your setup works:\n# For GitHub\nssh -T git@github.com\n\n# For GitLab\nssh -T git@gitlab.com\nYou should see a welcome message confirming successful authentication."
  },
  {
    "objectID": "blogs/gitsetup.html#step-3-create-your-first-local-repository",
    "href": "blogs/gitsetup.html#step-3-create-your-first-local-repository",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Step 3: Create Your First Local Repository",
    "text": "Step 3: Create Your First Local Repository\n\nNavigate to Your Project Directory\ncd /path/to/your/project\n# or create a new directory\nmkdir my-awesome-project\ncd my-awesome-project\n\n\nInitialize Git Repository\ngit init\nThis creates a hidden .git folder that tracks your project’s history.\n\n\nCreate Your First Files\nIf starting from scratch:\n# Create a README file\necho \"# My Awesome Project\" &gt; README.md\n\n# Create a simple .gitignore\ncat &gt; .gitignore &lt;&lt; EOF\n# OS generated files\n.DS_Store\nThumbs.db\n\n# IDE files\n.vscode/\n.idea/\n\n# Dependencies\nnode_modules/\nEOF\n\n\nStage and Commit Your Changes\n# Stage all files\ngit add .\n\n# Create your first commit\ngit commit -m \"Initial commit: Add README and .gitignore\"\nGood commit message practices: - Use present tense (“Add feature” not “Added feature”) - Keep the first line under 50 characters - Be descriptive but concise"
  },
  {
    "objectID": "blogs/gitsetup.html#step-4-connect-to-remote-repository",
    "href": "blogs/gitsetup.html#step-4-connect-to-remote-repository",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Step 4: Connect to Remote Repository",
    "text": "Step 4: Connect to Remote Repository\n\nCreate Remote Repository\n\nGo to your Git hosting service (GitHub/GitLab)\nCreate a new repository\nImportant: Don’t initialize with README, .gitignore, or license if you already have local commits\n\n\n\nLink Your Local Repository\ngit remote add origin git@github.com:yourusername/your-repo-name.git\n# Replace with your actual username and repository name\n\n\nCheck Your Default Branch\nModern Git uses main as the default branch, but older repos might use master:\ngit branch\nIf you’re on master but want to use main:\ngit branch -M main\n\n\nPush Your Code\nPush your local commits to the remote repository:\n# First push (sets up tracking)\ngit push -u origin main\n\n# Future pushes (after the -u flag is set)\ngit push\nThe -u flag (upstream) tells Git to remember this branch relationship, so future git push commands know where to go."
  },
  {
    "objectID": "blogs/gitsetup.html#daily-git-workflow",
    "href": "blogs/gitsetup.html#daily-git-workflow",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Daily Git Workflow",
    "text": "Daily Git Workflow\nOnce everything is set up, your typical workflow will be:\n# Make changes to your files\n# ...\n\n# Check what's changed\ngit status\n\n# Stage changes\ngit add .\n# or stage specific files\ngit add filename.txt\n\n# Commit with a descriptive message\ngit commit -m \"Add user authentication feature\"\n\n# Push to remote\ngit push\n\nUseful Git Commands\n# View commit history\ngit log --oneline\n\n# Check current status\ngit status\n\n# See what changes you've made\ngit diff\n\n# Undo changes to a file\ngit checkout -- filename.txt\n\n# Pull latest changes from remote\ngit pull"
  },
  {
    "objectID": "blogs/gitsetup.html#troubleshooting-common-issues",
    "href": "blogs/gitsetup.html#troubleshooting-common-issues",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Troubleshooting Common Issues",
    "text": "Troubleshooting Common Issues\n\nPermission Denied (SSH)\n\nEnsure your SSH key is added to ssh-agent: ssh-add -l\nVerify the key is added to your Git hosting service\nTest SSH connection: ssh -T git@github.com\n\n\n\nRemote Already Exists\nIf you get “remote origin already exists”:\ngit remote remove origin\ngit remote add origin git@github.com:username/repo.git\n\n\nWrong Branch Name\nIf your local branch doesn’t match remote expectations:\n# Rename current branch\ngit branch -M main\ngit push -u origin main"
  },
  {
    "objectID": "blogs/gitsetup.html#security-best-practices",
    "href": "blogs/gitsetup.html#security-best-practices",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Security Best Practices",
    "text": "Security Best Practices\n\nUse SSH keys instead of passwords for authentication\nSet passphrases on your SSH keys for additional security\nRegularly rotate your SSH keys (annually recommended)\nNever commit sensitive data like passwords or API keys\nUse .gitignore to exclude sensitive files\nReview commits before pushing to avoid accidentally including secrets"
  },
  {
    "objectID": "blogs/gitsetup.html#next-steps",
    "href": "blogs/gitsetup.html#next-steps",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Next Steps",
    "text": "Next Steps\nNow that you have Git and SSH configured:\n\nLearn about branching and merging for collaborative development\nExplore pull requests/merge requests for code review workflows\nSet up automated backups of your repositories\nConsider using Git hooks for automated testing\nLearn about conventional commits for better commit messages"
  },
  {
    "objectID": "blogs/gitsetup.html#conclusion",
    "href": "blogs/gitsetup.html#conclusion",
    "title": "Complete Git and SSH Setup Guide: From Zero to Push",
    "section": "Conclusion",
    "text": "Conclusion\nCongratulations! You’ve successfully set up Git with SSH authentication and created your first repository. This foundation will serve you well throughout your development journey. Remember, Git is a powerful tool that becomes more valuable as you learn its advanced features, but these basics will handle 90% of your daily needs.\nHappy coding! 🚀"
  },
  {
    "objectID": "blogs/mice.html#tldr",
    "href": "blogs/mice.html#tldr",
    "title": "From Missing to Meaningful: Beginner’s Guide to Multiple Imputation",
    "section": "TL;DR",
    "text": "TL;DR\n\nProblem: Missing data can bias results and reduce statistical power.\nSolution: Multiple Imputation fills in missing values multiple times to reflect uncertainty.\nTool: The mice package in R makes this easy and flexible.\nSteps:\n\nInspect missing data (md.pattern)\nImpute with mice() using methods like pmm, norm, cart, etc.\nAnalyze each imputed dataset\nPool results for final inference\nUse Cases: Surveys, clinical trials, social science data, etc.\n\n\nAssumptions: Data is Missing at Random (MAR)\nLimitations: Computational cost, model sensitivity, assumption of MAR"
  },
  {
    "objectID": "blogs/gwas.html",
    "href": "blogs/gwas.html",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "",
    "text": "Genome-wide association studies (GWAS) are powerful tools for uncovering genetic variants linked to traits and diseases. After preliminary quality control (QC), additional checks and thoughtful modeling are essential—especially when dealing with related individuals and population structure.\nThis guide walks through:\n\nPost-QC checks\nPhenotype and covariate preparation\nGWAS using SAIGE\nAlternatives to SAIGE\nVisualization and interpretation"
  },
  {
    "objectID": "blogs/gwas.html#introduction",
    "href": "blogs/gwas.html#introduction",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "",
    "text": "Genome-wide association studies (GWAS) are powerful tools for uncovering genetic variants linked to traits and diseases. After preliminary quality control (QC), additional checks and thoughtful modeling are essential—especially when dealing with related individuals and population structure.\nThis guide walks through:\n\nPost-QC checks\nPhenotype and covariate preparation\nGWAS using SAIGE\nAlternatives to SAIGE\nVisualization and interpretation"
  },
  {
    "objectID": "blogs/gwas.html#what-youve-received",
    "href": "blogs/gwas.html#what-youve-received",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "What You’ve Received",
    "text": "What You’ve Received\nBefore diving into the analysis, ensure you have:\n\nGenotype data (after basic QC)\nPhenotype file\nCovariates including PC1–PC20\nRelated individuals in the cohort"
  },
  {
    "objectID": "blogs/gwas.html#post-qc-checks",
    "href": "blogs/gwas.html#post-qc-checks",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "Post-QC Checks",
    "text": "Post-QC Checks\n\n1. Sample Matching\nEnsure sample IDs match across genotype and phenotype files.\ncomm -12 &lt;(cut -f1 phenotype.txt | sort) &lt;(cut -f1 genotype.fam | sort) &gt; common_ids.txt\n\n\n2. Sex Check\ncomm -12 &lt;(cut -f1 phenotype.txt | sort) &lt;(cut -f1 genotype.fam | sort) &gt; common_ids.txt\n\n\n3. Population Stratification\nYou already have PC1–PC20, so no need to compute PCA again. Just include these as covariates in your model.\n\n\n4. Relatedness\nSince your cohort includes related individuals, do not remove them. Instead, use a mixed model approach like SAIGE to account for relatedness."
  },
  {
    "objectID": "blogs/gwas.html#gwas-with-saige",
    "href": "blogs/gwas.html#gwas-with-saige",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "GWAS with SAIGE",
    "text": "GWAS with SAIGE\n\nWhy Choose SAIGE?\nSAIGE is particularly well-suited for complex datasets because it:\n\nHandles case-control imbalance effectively\nAccounts for relatedness using a sparse GRM\nScales to large datasets efficiently\nSupports both binary and quantitative traits\n\n\n\nConducting GWAS with SAIGE\nYou can follow the comprehensive guide to perform GWAS from their well-documented page."
  },
  {
    "objectID": "blogs/gwas.html#alternatives-to-saige",
    "href": "blogs/gwas.html#alternatives-to-saige",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "Alternatives to SAIGE",
    "text": "Alternatives to SAIGE\nDepending on your specific needs, consider these alternatives:\n\n\n\n\n\n\n\n\nTool\nBest For\nNotes\n\n\n\n\nPLINK\nSmall datasets, basic GWAS\nFast, but doesn’t handle relatedness\n\n\nGEMMA\nMixed models, quantitative traits\nHandles relatedness well\n\n\nBOLT-LMM\nLarge-scale quantitative traits\nFast, limited binary trait support\n\n\nREGENIE\nBinary and quantitative traits\nScalable, supports stepwise modeling"
  },
  {
    "objectID": "blogs/gwas.html#output-expectations",
    "href": "blogs/gwas.html#output-expectations",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "Output Expectations",
    "text": "Output Expectations\nAfter running your GWAS, you should expect:\n\nGWAS results: SNP ID, effect size, SE, p-value\nManhattan plot and QQ plot for visualization\nAdditional visualizations: Regional plots, volcano plots, etc.\n\n\nCreating Manhattan Plots\nThere are several online resources that input summary statistics and output Manhattan plots.\nPersonally, I opted for an in-house developed modified version of an R package used by research groups in the department.\nlibrary(qqman)\n\ngwas &lt;- read.table(\"gwas_results.txt\", header = TRUE) \n\nmanhattan(gwas, chr=\"CHR\", bp=\"BP\", snp=\"SNP\", p=\"P\", main=\"GWAS Manhattan Plot\") \n\nqq(gwas$P)\nThe output could look similar to the following plots:\n\n\n\n\n\n\n\nFigure 1: Manhattan Plot with red color indicating previously known loci and blue are the novel loci\n\n\n\n\n\n\n\n\n\n\nFigure 2: QQ Plot with a genomic correction value of 1.14\n\n\n\n\n\n\nNote: Taken from publication."
  },
  {
    "objectID": "blogs/gwas.html#downstream-checks-in-gwas",
    "href": "blogs/gwas.html#downstream-checks-in-gwas",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "Downstream Checks in GWAS",
    "text": "Downstream Checks in GWAS\nOnce you’ve run your GWAS and identified significant associations, it’s important to assess the overall genetic architecture of the trait. Two key downstream checks are heritability estimation and LD Score Regression (LDSC).\n\nSNP-Based Heritability\nHeritability refers to the proportion of phenotypic variance in a trait that can be attributed to genetic variation. In GWAS, we often estimate SNP-based heritability, which considers only the common variants captured in the study.\n\nWhy it matters: It helps quantify how much of the trait is explained by the genotyped SNPs.\nTools: Common tools include GCTA, LDSC, and REML.\nExample: If SNP-based heritability is 0.25, it means 25% of the trait variance is explained by the SNPs used in the GWAS.\n\n\n\nLD Score Regression (LDSC)\nLD Score Regression is a method to distinguish true polygenic signal from confounding biases (like population stratification or cryptic relatedness).\n\nLD Score: A measure of how much a SNP tags nearby variants due to linkage disequilibrium (LD).\nKey Insight: If a trait is polygenic, SNPs with higher LD scores should have higher test statistics.\nIntercept: LDSC provides an intercept value that helps detect inflation due to confounding. An intercept close to 1 suggests minimal confounding.\nApplications:\n\nEstimating SNP heritability from summary statistics.\nPartitioning heritability across functional annotations.\nGenetic correlation between traits.\n\n\n\n\nLDSC Command\nldsc.py \\\n  --h2 sumstats.txt \\\n  --ref-ld-chr eur_w_ld_chr/ \\\n  --w-ld-chr eur_w_ld_chr/ \\\n  --out trait_heritability\n\n\nInterpretation\nLDSC helps you understand whether your GWAS results reflect true polygenic signal or are inflated due to confounding. Here’s how to interpret the main components:\n1. Heritability Estimate (\\(h^2\\))\nWhat it means: The proportion of phenotypic variance explained by all SNPs in your GWAS.\nInterpretation:\n\n\n\n\n\n\n\nHeritability Value\nMeaning\n\n\n\n\n&gt; 0.2\nStrong polygenic contribution\n\n\n&lt; 0.2\nLimited genetic influence or insufficient power\n\n\n\nNote: This is SNP-based heritability, not total heritability (which includes rare variants and other sources).\n\n2. Intercept\nWhat it means: Measures inflation in test statistics not due to polygenicity.\nIdeal value: Close to 1.0.\nInterpretation:\n\n\n\n\n\n\n\nIntercept Value\nMeaning\n\n\n\n\n≈ 1.0\nMinimal confounding; inflation is likely due to true polygenic signal.\n\n\n&gt; 1.0\nSuggests confounding (e.g., population stratification, cryptic relatedness).\n\n\n\nAction: If high, consider improving QC (e.g., more principal components, better ancestry matching).\n3. LDSC Ratio\nThe LDSC ratio is calculated as:\n\\[\n\\text{Ratio} = \\frac{\\text{Intercept} - 1}{\\text{Mean}(\\chi^2) - 1}\n\\]\nInterpretation:\n\n\n\n\n\n\n\n\nRatio Value\nMeaning\nAction\n\n\n\n\n&lt; 0.1\nMost inflation is due to true polygenic signal.\n✅ Your GWAS is likely well-controlled.\n\n\n0.1 – 0.3\nSome inflation may be due to confounding.\n⚠️ Consider checking population structure and relatedness.\n\n\n&gt; 0.3\nA large portion of inflation is likely due to confounding.\n❌ Revisit QC steps, include more PCs, or refine your model.\n\n\n\n 4. Test Statistic vs LD Score Plot\n\n\n\n\n\n\n\n\nTrend Type\nPlot\nInterpretation\n\n\n\n\nUpward Trend\n\nIndicates polygenic signal — SNPs with higher LD scores have higher test statistics.\n\n\nFlat/Noisy Trend\n\nSuggests lack of polygenicity or presence of confounding factors.\n\n\n\n\n\nSummary of LD Score Regression Metrics\n\n\n\n\n\n\n\n\n\nMetric\nIdeal Value\nWhat It Means\nInterpretation & Action\n\n\n\n\nHeritability (\\(h^2\\))\n&gt; 0.1\nProportion of trait variance explained by SNPs\nLow value → trait may be weakly polygenic or underpowered study\n\n\nIntercept\n≈ 1.0\nInflation in test statistics not due to polygenicity\n&gt;1.0 → possible confounding (e.g., population stratification)\n\n\nRatio\n&lt; 0.1\nFraction of inflation due to confounding\n&gt;0.3 → revisit QC, ancestry correction, or model assumptions\n\n\nLD Score Plot\nPositive slope\nRelationship between LD score and test statistic\nFlat/noisy → weak polygenic signal or confounding present"
  },
  {
    "objectID": "blogs/gwas.html#ldsc-command",
    "href": "blogs/gwas.html#ldsc-command",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "LDSC Command",
    "text": "LDSC Command\nldsc.py \\\n  --h2 sumstats.txt \\\n  --ref-ld-chr eur_w_ld_chr/ \\\n  --w-ld-chr eur_w_ld_chr/ \\\n  --out trait_heritability\n\nInterpretation\nHeritability estimate: Found in the .log file output.\nIntercept: If significantly &gt;1, consider revisiting population structure correction (e.g., using more PCs or better QC)."
  },
  {
    "objectID": "blogs/gwas.html#downstream-analysis-in-gwas",
    "href": "blogs/gwas.html#downstream-analysis-in-gwas",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "Downstream Analysis in GWAS",
    "text": "Downstream Analysis in GWAS\nOnce you’ve run your GWAS and identified significant associations, it’s important to assess the overall genetic architecture of the trait. Two key downstream analyses are heritability estimation and LD Score Regression (LDSC).\n\nSNP-Based Heritability\nHeritability refers to the proportion of phenotypic variance in a trait that can be attributed to genetic variation. In GWAS, we often estimate SNP-based heritability, which considers only the common variants captured in the study.\n\nWhy it matters: It helps quantify how much of the trait is explained by the genotyped SNPs\nTools: Common tools include GCTA, LDSC, and REML\nExample: If SNP-based heritability is 0.25, it means 25% of the trait variance is explained by the SNPs used in the GWAS\n\n\n\nLD Score Regression (LDSC)\nLD Score Regression is a method to distinguish true polygenic signal from confounding biases (like population stratification or cryptic relatedness).\n\nLD Score: A measure of how much a SNP tags nearby variants due to linkage disequilibrium (LD)\nKey Insight: If a trait is polygenic, SNPs with higher LD scores should have higher test statistics\nIntercept: LDSC provides an intercept value that helps detect inflation due to confounding. An intercept close to 1 suggests minimal confounding\n\n\nLDSC Applications\n\nEstimating SNP heritability from summary statistics\nPartitioning heritability across functional annotations\nCalculating genetic correlation between traits\n\n\n\nLDSC Command\nldsc.py \\\n  --h2 sumstats.txt \\\n  --ref-ld-chr eur_w_ld_chr/ \\\n  --w-ld-chr eur_w_ld_chr/ \\\n  --out trait_heritability"
  },
  {
    "objectID": "blogs/gwas.html#interpreting-ldsc-results",
    "href": "blogs/gwas.html#interpreting-ldsc-results",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "Interpreting LDSC Results",
    "text": "Interpreting LDSC Results\nLDSC helps you understand whether your GWAS results reflect true polygenic signal or are inflated due to confounding. Here’s how to interpret the main components:\n\n1. Heritability Estimate (h²)\nWhat it means: The proportion of phenotypic variance explained by all SNPs in your GWAS.\n\n\n\n\n\n\n\nHeritability Value\nMeaning\n\n\n\n\n&gt; 0.2\nStrong polygenic contribution\n\n\n&lt; 0.2\nLimited genetic influence or insufficient power\n\n\n\n\nNote: This is SNP-based heritability, not total heritability (which includes rare variants and other sources).\n\n\n\n2. Intercept\nWhat it means: Measures inflation in test statistics not due to polygenicity.\nIdeal value: Close to 1.0\n\n\n\n\n\n\n\nIntercept Value\nMeaning\n\n\n\n\n≈ 1.0\nMinimal confounding; inflation is likely due to true polygenic signal\n\n\n&gt; 1.0\nSuggests confounding (e.g., population stratification, cryptic relatedness)\n\n\n\nAction: If high, consider improving QC (e.g., more principal components, better ancestry matching).\n\n\n3. LDSC Ratio\nThe LDSC ratio is calculated as:\n\\[\n\\text{Ratio} = \\frac{\\text{Intercept} - 1}{\\text{Mean}(\\chi^2) - 1}\n\\]\n\n\n\n\n\n\n\n\nRatio Value\nMeaning\nAction\n\n\n\n\n&lt; 0.1\nMost inflation is due to true polygenic signal\n✅ Your GWAS is likely well-controlled\n\n\n0.1 – 0.3\nSome inflation may be due to confounding\n⚠️ Consider checking population structure and relatedness\n\n\n&gt; 0.3\nA large portion of inflation is likely due to confounding\n❌ Revisit QC steps, include more PCs, or refine your model\n\n\n\n\n\n4. Test Statistic vs LD Score Plot\n\n\n\n\n\n\n\n\nTrend Type\nPlot\nInterpretation\n\n\n\n\nUpward Trend\n\nIndicates polygenic signal — SNPs with higher LD scores have higher test statistics\n\n\nFlat/Noisy Trend\n\nSuggests lack of polygenicity or presence of confounding factors"
  },
  {
    "objectID": "blogs/gwas.html#summary-ld-score-regression-metrics",
    "href": "blogs/gwas.html#summary-ld-score-regression-metrics",
    "title": "Beyond QC: A Practical Guide to GWAS with SAIGE",
    "section": "Summary: LD Score Regression Metrics",
    "text": "Summary: LD Score Regression Metrics\n\n\n\n\n\n\n\n\n\nMetric\nIdeal Value\nWhat It Means\nInterpretation & Action\n\n\n\n\nHeritability (h²)\n&gt; 0.1\nProportion of trait variance explained by SNPs\nLow value → trait may be weakly polygenic or underpowered study\n\n\nIntercept\n≈ 1.0\nInflation in test statistics not due to polygenicity\n&gt;1.0 → possible confounding (e.g., population stratification)\n\n\nRatio\n&lt; 0.1\nFraction of inflation due to confounding\n&gt;0.3 → revisit QC, ancestry correction, or model assumptions\n\n\nLD Score Plot\nPositive slope\nRelationship between LD score and test statistic\nFlat/noisy → weak polygenic signal or confounding present"
  }
]